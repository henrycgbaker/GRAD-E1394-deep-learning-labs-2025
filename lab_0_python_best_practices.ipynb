{
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 0: Python Best Practices for Deep Learning\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "1. Write type-annotated Python functions using modern syntax\n",
    "2. Apply Pythonic patterns (comprehensions, context managers, enumerate/zip)\n",
    "3. Perform NumPy array operations including broadcasting and reshaping\n",
    "4. Understand OOP conventions used in PyTorch (classes, `__call__`, etc.)\n",
    "5. Write generators for memory-efficient data processing\n",
    "6. Debug Python code effectively\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic Python programming (variables, loops, functions, classes)\n",
    "- Familiarity with importing packages\n",
    "\n",
    "## Why This Lab?\n",
    "\n",
    "Deep learning code has conventions that may be unfamiliar:\n",
    "- **Type hints** make code self-documenting and catch bugs early\n",
    "- **NumPy broadcasting** is essential for understanding tensor operations\n",
    "- **Generators** power PyTorch DataLoaders\n",
    "- **OOP patterns** like `__call__` are central to `nn.Module`\n",
    "\n",
    "This lab ensures you have the Python foundations needed for Labs 6-10."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ==== Environment Setup ====\n",
    "import os\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Running on Google Colab\")\n",
    "else:\n",
    "    print(\"Running locally\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ==== Device Setup ====\n",
    "import torch\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"Get best available device: CUDA > MPS > CPU.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print(f\"Using CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "        print(\"Using Apple MPS (Metal)\")\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print(\"Using CPU\")\n",
    "    return device\n",
    "\n",
    "DEVICE = get_device()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Python Foundations for Deep Learning\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 Type Hints\n",
    "\n",
    "Type hints make code self-documenting and enable better IDE support.\n",
    "\n",
    "### Basic Syntax (Python 3.10+)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Basic type hints\n",
    "def greet(name: str) -> str:\n",
    "    return f\"Hello, {name}!\"\n",
    "\n",
    "# Collections - use lowercase (Python 3.10+)\n",
    "def average(values: list[float]) -> float:\n",
    "    return sum(values) / len(values)\n",
    "\n",
    "# Dictionaries\n",
    "def word_count(text: str) -> dict[str, int]:\n",
    "    words = text.lower().split()\n",
    "    return {word: words.count(word) for word in set(words)}\n",
    "\n",
    "# Optional values (can be None)\n",
    "def find_index(items: list[str], target: str) -> int | None:\n",
    "    try:\n",
    "        return items.index(target)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Test\n",
    "print(f\"greet('World'): {greet('World')}\")\n",
    "print(f\"average([1, 2, 3, 4, 5]): {average([1, 2, 3, 4, 5])}\")\n",
    "print(f\"word_count('the cat and the dog'): {word_count('the cat and the dog')}\")\n",
    "print(f\"find_index(['a', 'b', 'c'], 'b'): {find_index(['a', 'b', 'c'], 'b')}\")\n",
    "print(f\"find_index(['a', 'b', 'c'], 'x'): {find_index(['a', 'b', 'c'], 'x')}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Q: Why use `int | None` instead of `Optional[int]`?</b></summary>\n",
    "\n",
    "**A:** `int | None` is the modern Python 3.10+ syntax. It's more readable and doesn't require importing from `typing`. The older `Optional[int]` still works but is more verbose.\n",
    "\n",
    "```python\n",
    "# Old style (pre-3.10)\n",
    "from typing import Optional, List\n",
    "def f(x: Optional[int]) -> List[str]: ...\n",
    "\n",
    "# Modern style (3.10+)\n",
    "def f(x: int | None) -> list[str]: ...\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Docstrings\n",
    "\n",
    "Use Google-style docstrings for complex functions:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    epochs: int = 10,\n",
    "    learning_rate: float = 0.001,\n",
    "    verbose: bool = True\n",
    ") -> dict[str, list[float]]:\n",
    "    \"\"\"\n",
    "    Train a PyTorch model.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model to train (nn.Module)\n",
    "        train_loader: DataLoader with training data\n",
    "        epochs: Number of training epochs\n",
    "        learning_rate: Learning rate for optimizer\n",
    "        verbose: Whether to print progress\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with 'train_loss' history\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If epochs < 1\n",
    "    \n",
    "    Example:\n",
    "        >>> history = train_model(model, loader, epochs=5)\n",
    "        >>> plt.plot(history['train_loss'])\n",
    "    \"\"\"\n",
    "    if epochs < 1:\n",
    "        raise ValueError(\"epochs must be >= 1\")\n",
    "    # ... training code ...\n",
    "    return {\"train_loss\": []}\n",
    "\n",
    "# For simple/obvious functions, a one-liner is fine:\n",
    "def relu(x: float) -> float:\n",
    "    \"\"\"Return max(0, x).\"\"\"\n",
    "    return max(0, x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Pythonic Patterns\n",
    "\n",
    "### List Comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Instead of:\n",
    "squares_loop = []\n",
    "for i in range(10):\n",
    "    squares_loop.append(i ** 2)\n",
    "\n",
    "# Use:\n",
    "squares = [i ** 2 for i in range(10)]\n",
    "print(f\"Squares: {squares}\")\n",
    "\n",
    "# With condition\n",
    "evens = [i for i in range(20) if i % 2 == 0]\n",
    "print(f\"Evens: {evens}\")\n",
    "\n",
    "# Dict comprehension\n",
    "word_lengths = {word: len(word) for word in [\"cat\", \"elephant\", \"dog\"]}\n",
    "print(f\"Word lengths: {word_lengths}\")\n",
    "\n",
    "# Set comprehension (removes duplicates)\n",
    "unique_lengths = {len(word) for word in [\"cat\", \"bat\", \"elephant\", \"ant\"]}\n",
    "print(f\"Unique lengths: {unique_lengths}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### enumerate, zip, sorted"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# enumerate - get index and value\n",
    "fruits = [\"apple\", \"banana\", \"cherry\"]\n",
    "for i, fruit in enumerate(fruits):\n",
    "    print(f\"{i}: {fruit}\")\n",
    "\n",
    "# zip - iterate multiple sequences together\n",
    "names = [\"Alice\", \"Bob\", \"Charlie\"]\n",
    "scores = [85, 92, 78]\n",
    "for name, score in zip(names, scores):\n",
    "    print(f\"{name}: {score}\")\n",
    "\n",
    "# sorted with key function\n",
    "students = [(\"Alice\", 85), (\"Bob\", 92), (\"Charlie\", 78)]\n",
    "by_score = sorted(students, key=lambda x: x[1], reverse=True)\n",
    "print(f\"By score (desc): {by_score}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Q: When should you use a list comprehension vs a regular loop?</b></summary>\n",
    "\n",
    "**A:** Use comprehensions when:\n",
    "- Building a new list/dict/set from an iterable\n",
    "- The logic fits on one readable line\n",
    "\n",
    "Use regular loops when:\n",
    "- You need complex logic or multiple statements\n",
    "- You're modifying in place rather than creating new\n",
    "- Readability suffers from one-liner\n",
    "\n",
    "**Rule of thumb:** If you can't understand it in 5 seconds, use a loop.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Managers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Context managers ensure cleanup (files close, locks release, etc.)\n",
    "\n",
    "# File I/O - always use 'with'\n",
    "from pathlib import Path\n",
    "\n",
    "# Write\n",
    "with open(\"test.txt\", \"w\") as f:\n",
    "    f.write(\"Hello, World!\")\n",
    "\n",
    "# Read\n",
    "with open(\"test.txt\", \"r\") as f:\n",
    "    content = f.read()\n",
    "print(f\"File content: {content}\")\n",
    "\n",
    "# Clean up\n",
    "Path(\"test.txt\").unlink()\n",
    "\n",
    "# PyTorch example: disable gradients for inference\n",
    "import torch\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = x * 2  # No gradient tracking here\n",
    "print(f\"y.requires_grad: {y.requires_grad}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Basic try/except\n",
    "def safe_divide(a: float, b: float) -> float | None:\n",
    "    try:\n",
    "        return a / b\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Warning: Division by zero\")\n",
    "        return None\n",
    "\n",
    "print(safe_divide(10, 2))\n",
    "print(safe_divide(10, 0))\n",
    "\n",
    "# Multiple exception types\n",
    "def parse_int(s: str) -> int:\n",
    "    try:\n",
    "        return int(s)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Cannot parse '{s}' as integer\")\n",
    "    except TypeError:\n",
    "        raise TypeError(f\"Expected string, got {type(s)}\")\n",
    "\n",
    "# finally - always runs (cleanup)\n",
    "def read_with_cleanup(filename: str) -> str:\n",
    "    f = None\n",
    "    try:\n",
    "        f = open(filename, \"r\")\n",
    "        return f.read()\n",
    "    except FileNotFoundError:\n",
    "        return \"\"\n",
    "    finally:\n",
    "        if f:\n",
    "            f.close()\n",
    "            print(\"File closed\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Q: When should you catch exceptions vs let them propagate?</b></summary>\n",
    "\n",
    "**A:** \n",
    "- **Catch** when you can handle it meaningfully (retry, default value, cleanup)\n",
    "- **Propagate** when the caller should decide how to handle it\n",
    "\n",
    "**Bad:** Catching everything and hiding errors\n",
    "```python\n",
    "try:\n",
    "    result = do_something()\n",
    "except:  # Never do this!\n",
    "    pass\n",
    "```\n",
    "\n",
    "**Good:** Catch specific exceptions you can handle\n",
    "```python\n",
    "try:\n",
    "    data = load_file(path)\n",
    "except FileNotFoundError:\n",
    "    data = default_data\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: NumPy Essentials\n",
    "\n",
    "NumPy is the foundation for all deep learning frameworks. Understanding it is essential.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.1 Why NumPy Matters for Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Vectorization is MUCH faster than loops\n",
    "size = 1_000_000\n",
    "\n",
    "# Loop version\n",
    "a_list = list(range(size))\n",
    "b_list = list(range(size))\n",
    "\n",
    "start = time.time()\n",
    "c_list = [a + b for a, b in zip(a_list, b_list)]\n",
    "loop_time = time.time() - start\n",
    "\n",
    "# NumPy version\n",
    "a_np = np.arange(size)\n",
    "b_np = np.arange(size)\n",
    "\n",
    "start = time.time()\n",
    "c_np = a_np + b_np\n",
    "numpy_time = time.time() - start\n",
    "\n",
    "print(f\"Loop time: {loop_time:.4f}s\")\n",
    "print(f\"NumPy time: {numpy_time:.4f}s\")\n",
    "print(f\"NumPy is {loop_time/numpy_time:.1f}x faster\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Array Creation & Indexing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Creating arrays\n",
    "a = np.array([1, 2, 3, 4, 5])          # From list\n",
    "b = np.zeros((3, 4))                     # 3x4 zeros\n",
    "c = np.ones((2, 3))                      # 2x3 ones\n",
    "d = np.arange(0, 10, 2)                  # [0, 2, 4, 6, 8]\n",
    "e = np.linspace(0, 1, 5)                 # 5 points from 0 to 1\n",
    "f = np.random.randn(3, 3)                # 3x3 standard normal\n",
    "\n",
    "print(f\"zeros shape: {b.shape}\")\n",
    "print(f\"arange: {d}\")\n",
    "print(f\"linspace: {e}\")\n",
    "\n",
    "# Indexing\n",
    "arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(f\"\\narr:\\n{arr}\")\n",
    "print(f\"arr[0, 1]: {arr[0, 1]}\")         # Single element\n",
    "print(f\"arr[0, :]: {arr[0, :]}\")         # First row\n",
    "print(f\"arr[:, 1]: {arr[:, 1]}\")         # Second column\n",
    "print(f\"arr[0:2, 1:3]:\\n{arr[0:2, 1:3]}\")  # Subarray\n",
    "\n",
    "# Boolean indexing\n",
    "print(f\"\\narr > 5: {arr[arr > 5]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Broadcasting\n",
    "\n",
    "Broadcasting allows operations between arrays of different shapes.\n",
    "\n",
    "### Rules:\n",
    "1. Compare shapes from right to left\n",
    "2. Dimensions match if they're equal OR one of them is 1\n",
    "3. Missing dimensions are treated as 1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Scalar broadcasts to any shape\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])  # Shape: (2, 3)\n",
    "print(f\"a + 10:\\n{a + 10}\")  # 10 broadcasts to (2, 3)\n",
    "\n",
    "# Row vector broadcasts across rows\n",
    "row = np.array([100, 200, 300])  # Shape: (3,)\n",
    "print(f\"\\na + row:\\n{a + row}\")  # (3,) -> (2, 3)\n",
    "\n",
    "# Column vector broadcasts across columns\n",
    "col = np.array([[10], [20]])  # Shape: (2, 1)\n",
    "print(f\"\\na + col:\\n{a + col}\")  # (2, 1) -> (2, 3)\n",
    "\n",
    "# Outer product via broadcasting\n",
    "x = np.array([1, 2, 3])[:, np.newaxis]  # Shape: (3, 1)\n",
    "y = np.array([10, 20])                   # Shape: (2,)\n",
    "print(f\"\\nOuter product (x * y):\\n{x * y}\")  # (3, 1) * (2,) -> (3, 2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Q: Why does `np.array([1,2]) + np.array([[1],[2],[3]])` work?</b></summary>\n",
    "\n",
    "**A:** Let's trace the broadcasting:\n",
    "- Left: shape (2,)\n",
    "- Right: shape (3, 1)\n",
    "\n",
    "Align from right:\n",
    "```\n",
    "     (2,)  ->  (1, 2)  [add dimension]\n",
    "  (3, 1)   ->  (3, 1)\n",
    "  Result:      (3, 2)  [both expand]\n",
    "```\n",
    "\n",
    "Each expands where it has size 1:\n",
    "```python\n",
    "[[1, 2],      [[1, 1],     [[2, 3],\n",
    " [1, 2],  +    [2, 2],  =   [3, 4],\n",
    " [1, 2]]       [3, 3]]      [4, 5]]\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Broadcasting\n",
    "\n",
    "Fix the code to add bias to each sample:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data: 100 samples, 784 features (like MNIST flattened)\n",
    "X = np.random.randn(100, 784)\n",
    "bias = np.random.randn(784)\n",
    "\n",
    "# This should add bias to each row\n",
    "result = X + bias  # Does this work?\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"bias shape: {bias.shape}\")\n",
    "print(f\"result shape: {result.shape}\")\n",
    "assert result.shape == (100, 784), \"Shape mismatch!\"\n",
    "print(\"Broadcasting worked!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Common Operations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(f\"Original shape: {a.shape}\")\n",
    "\n",
    "# Reshape\n",
    "b = a.reshape(3, 2)\n",
    "print(f\"Reshaped to (3,2):\\n{b}\")\n",
    "\n",
    "# Transpose\n",
    "print(f\"Transposed:\\n{a.T}\")\n",
    "\n",
    "# Flatten\n",
    "print(f\"Flattened: {a.flatten()}\")\n",
    "\n",
    "# Concatenate\n",
    "c = np.array([[7, 8, 9]])\n",
    "print(f\"\\nVertical concat:\\n{np.concatenate([a, c], axis=0)}\")\n",
    "\n",
    "d = np.array([[10], [20]])\n",
    "print(f\"\\nHorizontal concat:\\n{np.concatenate([a, d], axis=1)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Reductions along axes\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(f\"Array:\\n{a}\")\n",
    "\n",
    "print(f\"\\nSum all: {a.sum()}\")\n",
    "print(f\"Sum rows (axis=1): {a.sum(axis=1)}\")     # Sum each row\n",
    "print(f\"Sum cols (axis=0): {a.sum(axis=0)}\")     # Sum each column\n",
    "\n",
    "print(f\"\\nMean all: {a.mean():.2f}\")\n",
    "print(f\"Mean rows: {a.mean(axis=1)}\")\n",
    "\n",
    "# Matrix multiplication\n",
    "W = np.random.randn(3, 4)  # 3x4\n",
    "x = np.random.randn(4, 2)  # 4x2\n",
    "y = W @ x                   # 3x2\n",
    "print(f\"\\nW @ x: {W.shape} @ {x.shape} = {y.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Q: What's the difference between `axis=0` and `axis=1` in reductions?</b></summary>\n",
    "\n",
    "**A:** The axis parameter specifies which dimension to \"collapse\":\n",
    "- `axis=0`: Collapse rows \u2192 result has shape of a single row\n",
    "- `axis=1`: Collapse columns \u2192 result has shape of a single column\n",
    "\n",
    "Think of it as: \"sum **along** this axis\" or \"reduce **this** dimension\"\n",
    "\n",
    "```python\n",
    "a = [[1, 2, 3],\n",
    "     [4, 5, 6]]  # Shape (2, 3)\n",
    "\n",
    "a.sum(axis=0)  # [5, 7, 9]   - summed down columns, shape (3,)\n",
    "a.sum(axis=1)  # [6, 15]     - summed across rows, shape (2,)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: OOP for Deep Learning\n",
    "\n",
    "PyTorch heavily uses OOP. Understanding these patterns is essential.\n",
    "\n",
    "---\n",
    "\n",
    "## 4.1 Classes Review"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"A simple neural network class demonstrating OOP patterns.\"\"\"\n",
    "    \n",
    "    # Class attribute (shared by all instances)\n",
    "    default_activation = \"relu\"\n",
    "    \n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n",
    "        \"\"\"Initialize the network.\"\"\"\n",
    "        # Instance attributes (unique to each instance)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Simulated weights\n",
    "        self.weights = {\n",
    "            \"W1\": np.random.randn(input_size, hidden_size) * 0.01,\n",
    "            \"W2\": np.random.randn(hidden_size, output_size) * 0.01,\n",
    "        }\n",
    "    \n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        h = x @ self.weights[\"W1\"]\n",
    "        h = np.maximum(0, h)  # ReLU\n",
    "        return h @ self.weights[\"W2\"]\n",
    "\n",
    "# Usage\n",
    "net = NeuralNetwork(784, 128, 10)\n",
    "x = np.random.randn(32, 784)  # Batch of 32\n",
    "output = net.forward(x)\n",
    "print(f\"Input: {x.shape} -> Output: {output.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Naming Conventions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class DataProcessor:\n",
    "    \"\"\"Demonstrates Python naming conventions.\"\"\"\n",
    "    \n",
    "    def __init__(self, data: list):\n",
    "        self.data = data              # Public: anyone can access\n",
    "        self._cache = {}              # Protected: internal use, but accessible\n",
    "        self.__secret = \"hidden\"      # Private: name-mangled to _DataProcessor__secret\n",
    "    \n",
    "    def process(self):\n",
    "        \"\"\"Public method - part of the API.\"\"\"\n",
    "        return self._preprocess()\n",
    "    \n",
    "    def _preprocess(self):\n",
    "        \"\"\"Protected method - internal helper, but subclasses can override.\"\"\"\n",
    "        return [x * 2 for x in self.data]\n",
    "    \n",
    "    def __validate(self):\n",
    "        \"\"\"Private method - truly internal, not for subclasses.\"\"\"\n",
    "        return all(isinstance(x, (int, float)) for x in self.data)\n",
    "\n",
    "dp = DataProcessor([1, 2, 3])\n",
    "print(f\"Public data: {dp.data}\")\n",
    "print(f\"Protected _cache: {dp._cache}\")  # Works but discouraged\n",
    "# print(dp.__secret)  # AttributeError!\n",
    "print(f\"Mangled name: {dp._DataProcessor__secret}\")  # How to access if needed"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Q: When should you use `_protected` vs `__private`?</b></summary>\n",
    "\n",
    "**A:**\n",
    "- **`_protected`**: Use for internal methods that subclasses might need to override. It's a convention saying \"internal, but accessible.\"\n",
    "\n",
    "- **`__private`**: Use when you truly want to prevent accidental override in subclasses. Python mangles the name to `_ClassName__method`, making it harder (but not impossible) to access.\n",
    "\n",
    "**In practice:** Most Python code uses `_protected`. Use `__private` sparingly.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Dunder Methods\n",
    "\n",
    "Dunder (double underscore) methods let you customize how objects behave."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class Tensor:\n",
    "    \"\"\"A simple tensor class demonstrating dunder methods.\"\"\"\n",
    "    \n",
    "    def __init__(self, data: list):\n",
    "        self.data = np.array(data)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"For developers - unambiguous representation.\"\"\"\n",
    "        return f\"Tensor(shape={self.data.shape}, dtype={self.data.dtype})\"\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"For users - readable representation.\"\"\"\n",
    "        return f\"Tensor with shape {self.data.shape}\"\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Enable len(tensor).\"\"\"\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Enable tensor[idx].\"\"\"\n",
    "        return self.data[idx]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        \"\"\"Enable tensor(x) - used heavily in PyTorch!\"\"\"\n",
    "        return self.data @ x\n",
    "\n",
    "t = Tensor([[1, 2], [3, 4]])\n",
    "print(f\"repr: {repr(t)}\")\n",
    "print(f\"str: {str(t)}\")\n",
    "print(f\"len: {len(t)}\")\n",
    "print(f\"t[0]: {t[0]}\")\n",
    "print(f\"t([1, 1]): {t(np.array([1, 1]))}\")  # Callable!"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Q: Why does PyTorch use `__call__` for the forward pass?</b></summary>\n",
    "\n",
    "**A:** In PyTorch, `model(x)` calls `model.__call__(x)`, which internally calls `model.forward(x)` but also handles:\n",
    "- Hooks (callbacks before/after forward)\n",
    "- Gradient tracking setup\n",
    "- Module state management\n",
    "\n",
    "This is why you define `forward()` but call `model(x)`, not `model.forward(x)`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Decorators"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class Model:\n",
    "    def __init__(self, name: str):\n",
    "        self._name = name\n",
    "        self._is_training = True\n",
    "    \n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        \"\"\"Property decorator - access like an attribute.\"\"\"\n",
    "        return self._name\n",
    "    \n",
    "    @property\n",
    "    def is_training(self) -> bool:\n",
    "        return self._is_training\n",
    "    \n",
    "    @is_training.setter\n",
    "    def is_training(self, value: bool):\n",
    "        \"\"\"Setter for property.\"\"\"\n",
    "        self._is_training = value\n",
    "        print(f\"Training mode: {value}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def count_parameters(weights: dict) -> int:\n",
    "        \"\"\"Static method - doesn't need self.\"\"\"\n",
    "        return sum(w.size for w in weights.values())\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config: dict):\n",
    "        \"\"\"Class method - alternative constructor.\"\"\"\n",
    "        return cls(name=config.get(\"name\", \"unnamed\"))\n",
    "\n",
    "# Usage\n",
    "m = Model(\"MyModel\")\n",
    "print(f\"Name: {m.name}\")  # Property access\n",
    "m.is_training = False     # Property setter\n",
    "\n",
    "m2 = Model.from_config({\"name\": \"ConfigModel\"})  # Classmethod\n",
    "print(f\"From config: {m2.name}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: Practical Patterns\n",
    "\n",
    "---\n",
    "\n",
    "## 5.1 Generators & Iterators\n",
    "\n",
    "Generators are crucial for memory-efficient data loading."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Generator function - uses yield\n",
    "def count_up_to(n: int):\n",
    "    \"\"\"Generate numbers from 0 to n-1.\"\"\"\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        yield i  # Pauses here, returns value\n",
    "        i += 1\n",
    "\n",
    "# Usage\n",
    "for num in count_up_to(5):\n",
    "    print(num, end=\" \")\n",
    "print()\n",
    "\n",
    "# Generator expression (like list comprehension but lazy)\n",
    "squares_gen = (x**2 for x in range(1000000))  # No memory allocated yet!\n",
    "print(f\"Generator: {squares_gen}\")\n",
    "print(f\"First 5: {[next(squares_gen) for _ in range(5)]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Why generators matter for DL: memory efficiency\n",
    "import sys\n",
    "\n",
    "# List stores all values in memory\n",
    "big_list = [i**2 for i in range(1000000)]\n",
    "print(f\"List size: {sys.getsizeof(big_list) / 1e6:.1f} MB\")\n",
    "\n",
    "# Generator computes on-demand\n",
    "def big_gen():\n",
    "    for i in range(1000000):\n",
    "        yield i**2\n",
    "\n",
    "gen = big_gen()\n",
    "print(f\"Generator size: {sys.getsizeof(gen)} bytes\")\n",
    "\n",
    "# DataLoader-style batching\n",
    "def batch_generator(data: list, batch_size: int):\n",
    "    \"\"\"Yield batches from data.\"\"\"\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i + batch_size]\n",
    "\n",
    "data = list(range(100))\n",
    "for batch in batch_generator(data, batch_size=32):\n",
    "    print(f\"Batch: {batch[:3]}... (size {len(batch)})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Q: When should you use a generator vs a list?</b></summary>\n",
    "\n",
    "**A:**\n",
    "- **Generator**: When data is large, you only need one pass, or values are computed on-demand\n",
    "- **List**: When you need random access, multiple passes, or the data is small\n",
    "\n",
    "**DataLoaders use generators** because:\n",
    "1. Training data is often huge (can't fit in RAM)\n",
    "2. You only need one batch at a time\n",
    "3. Data can be augmented on-the-fly\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 File I/O with Pathlib"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create paths (cross-platform!)\n",
    "data_dir = Path(\"data\")\n",
    "model_path = data_dir / \"models\" / \"best.pt\"\n",
    "\n",
    "print(f\"Path: {model_path}\")\n",
    "print(f\"Parent: {model_path.parent}\")\n",
    "print(f\"Name: {model_path.name}\")\n",
    "print(f\"Stem: {model_path.stem}\")\n",
    "print(f\"Suffix: {model_path.suffix}\")\n",
    "\n",
    "# Check existence\n",
    "print(f\"\\nExists: {model_path.exists()}\")\n",
    "print(f\"Is file: {model_path.is_file()}\")\n",
    "\n",
    "# Find files\n",
    "current = Path(\".\")\n",
    "print(f\"\\nPython files in current dir: {list(current.glob('*.py'))[:3]}\")\n",
    "print(f\"All .ipynb (recursive): {list(current.glob('**/*.ipynb'))[:3]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Debugging Strategies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 1. Print debugging with f-strings\n",
    "def debug_forward(x, W):\n",
    "    print(f\"DEBUG: x.shape={x.shape}, W.shape={W.shape}\")\n",
    "    result = x @ W\n",
    "    print(f\"DEBUG: result.shape={result.shape}\")\n",
    "    return result\n",
    "\n",
    "# 2. Assertions - catch bugs early\n",
    "def normalize(x: np.ndarray) -> np.ndarray:\n",
    "    assert x.ndim == 2, f\"Expected 2D array, got {x.ndim}D\"\n",
    "    assert x.shape[0] > 0, \"Empty array\"\n",
    "    return (x - x.mean(axis=0)) / (x.std(axis=0) + 1e-8)\n",
    "\n",
    "# 3. Shape annotations in comments\n",
    "def attention(Q, K, V):\n",
    "    # Q: (batch, heads, seq_len, d_k)\n",
    "    # K: (batch, heads, seq_len, d_k)\n",
    "    # V: (batch, heads, seq_len, d_v)\n",
    "    \n",
    "    scores = Q @ K.transpose(-2, -1)  # (batch, heads, seq_len, seq_len)\n",
    "    weights = scores  # Simplified - normally softmax\n",
    "    output = weights @ V  # (batch, heads, seq_len, d_v)\n",
    "    return output\n",
    "\n",
    "# Test\n",
    "x = np.random.randn(32, 784)\n",
    "W = np.random.randn(784, 128)\n",
    "y = debug_forward(x, W)\n",
    "z = normalize(x)\n",
    "print(f\"\\nNormalized shape: {z.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 6: Summary & Exercises\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "### Python Foundations\n",
    "- Use **type hints** (`def f(x: int) -> str`) for self-documenting code\n",
    "- Use **comprehensions** for building collections, loops for complex logic\n",
    "- Use **context managers** (`with`) for resource management\n",
    "- **Catch specific exceptions**, let others propagate\n",
    "\n",
    "### NumPy\n",
    "- **Vectorize** operations - avoid Python loops on arrays\n",
    "- **Broadcasting** aligns shapes from the right, expanding size-1 dimensions\n",
    "- **axis=0** collapses rows, **axis=1** collapses columns\n",
    "\n",
    "### OOP for DL\n",
    "- **`_protected`** for internal methods, **`__private`** rarely\n",
    "- **`__call__`** makes objects callable (used by `nn.Module`)\n",
    "- **`@property`** for computed attributes, **`@classmethod`** for alternative constructors\n",
    "\n",
    "### Practical Patterns\n",
    "- **Generators** for memory-efficient iteration (DataLoaders!)\n",
    "- **Pathlib** for cross-platform file paths\n",
    "- **Shape comments** for debugging tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Assessment Checklist\n",
    "\n",
    "Before proceeding to Lab 6, you should be able to:\n",
    "\n",
    "- [ ] Write a function with type hints and a Google-style docstring\n",
    "- [ ] Convert a loop to a list comprehension\n",
    "- [ ] Explain what `axis=0` vs `axis=1` means in NumPy reductions\n",
    "- [ ] Predict the output shape of broadcasting `(3,1) + (4,)`\n",
    "- [ ] Explain why `__call__` is used in PyTorch modules\n",
    "- [ ] Write a generator function with `yield`\n",
    "- [ ] Use `pathlib.Path` to construct file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Exercise: Mini Data Pipeline\n",
    "\n",
    "Implement a simple data pipeline using the concepts from this lab:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Exercise: Implement a data pipeline class\n",
    "\n",
    "class DataPipeline:\n",
    "    \"\"\"\n",
    "    A simple data pipeline for loading and batching data.\n",
    "    \n",
    "    TODO: Implement the following methods:\n",
    "    1. __init__: Store data and batch_size\n",
    "    2. __len__: Return number of batches\n",
    "    3. __iter__: Yield batches (use a generator!)\n",
    "    4. normalize: Normalize data using broadcasting\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data: np.ndarray, batch_size: int = 32):\n",
    "        # TODO: Store data and batch_size\n",
    "        pass\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # TODO: Return number of batches (hint: use ceiling division)\n",
    "        pass\n",
    "    \n",
    "    def __iter__(self):\n",
    "        # TODO: Yield batches of data\n",
    "        pass\n",
    "    \n",
    "    def normalize(self) -> np.ndarray:\n",
    "        # TODO: Return normalized data (zero mean, unit std per feature)\n",
    "        pass\n",
    "\n",
    "# Test your implementation:\n",
    "# data = np.random.randn(100, 784)\n",
    "# pipeline = DataPipeline(data, batch_size=32)\n",
    "# print(f\"Number of batches: {len(pipeline)}\")\n",
    "# for i, batch in enumerate(pipeline):\n",
    "#     print(f\"Batch {i}: shape {batch.shape}\")\n",
    "# normalized = pipeline.normalize()\n",
    "# print(f\"Mean after normalization: {normalized.mean(axis=0)[:5]}\")  # Should be ~0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "class DataPipeline:\n",
    "    def __init__(self, data: np.ndarray, batch_size: int = 32):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return (len(self.data) + self.batch_size - 1) // self.batch_size\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.data), self.batch_size):\n",
    "            yield self.data[i:i + self.batch_size]\n",
    "    \n",
    "    def normalize(self) -> np.ndarray:\n",
    "        mean = self.data.mean(axis=0)  # Shape: (784,)\n",
    "        std = self.data.std(axis=0)    # Shape: (784,)\n",
    "        return (self.data - mean) / (std + 1e-8)  # Broadcasting!\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. [Python Type Hints Cheat Sheet](https://mypy.readthedocs.io/en/stable/cheat_sheet_py3.html)\n",
    "2. [NumPy Broadcasting Rules](https://numpy.org/doc/stable/user/basics.broadcasting.html)\n",
    "3. [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html)\n",
    "4. [Real Python - Generators](https://realpython.com/introduction-to-python-generators/)\n",
    "5. [PyTorch nn.Module Source](https://github.com/pytorch/pytorch/blob/main/torch/nn/modules/module.py)\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Lab 6 - RNN Foundations"
   ]
  }
 ]
}